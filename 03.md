# Ultra-low-power wake-up word on the ESP32-S3

*This article assumes basic familiarity with: ESP32-series SoC and the ESP-IDF framework; register-level microcontroller operation; the I2S protocol.*

## The challenge

**Accurately detect a wake-up word on the ESP32-S3 with as little power as possible.**

In this project, a major engineering challenge lies in low-power continuous listening — the device stays for hours and even days idle while ready to wake up to a call anytime, so reducing the power consumption in this state is paramount for prolonged operation with a small battery. Conversely, power during interaction is less of a concern as the sessions run only in short bursts (around one minute each time).

Hardware consists of: **ESP32-S3-PICO-1**, a highly integrated wireless-enabled system-in-a-package; and **INMP441**, an MEMS microphone acting as an I2S peripheral device — when supplied with a bus clock (WS and BCK signals), it outputs the digital audio for us to process.

In sleep mode, we only need to listen for the wake-up word (小鸭小鸭 *xiǎoyā xiǎoyā*). This is handled by Espressif's [ESP-SR](https://github.com/espressif/esp-sr) library, which has [generously provided a model](https://github.com/espressif/esp-sr/issues/88#issuecomment-2506974739) for this specific phrase. All we need is to feed digital audio samples (16-kHz, 16-bit, mono) into the library and retrieve a binary wake-up signal. However, ESP32-S3 consumes tens of milliamperes for the task, due to the SoC's sleep mode preventing I2S peripheral operation (most peripherals, including I2S and DMA, [are clock gated](https://docs.espressif.com/projects/esp-idf/en/v5.5.1/esp32s3/api-guides/low-power-mode/low-power-mode-soc.html) in light sleep). We need a solution that permits us to at least go into light sleep. The ESP-SR detection model requires CPU and thus cannot run in sleep; still, we can keep inspecting the audio with the main processor sleeping, and wake it up when someone speaks, so that the model runs to determine whether the wake word has been said. In this way, the main processor is only intermittently loaded, spending most of the time in sleep. This is a classic task of voice activity detection (VAD).

Our requirements are thus as follows:
- Maintain a Wi-Fi connection (as STA);
- Keep an I2S clock (WS & BCK) running;
- Monitor I2S audio data for voice activity, i.e., VAD;
- Do all the above with the main processor sleeping, using as little power as possible.

We will solve this one by one.

## The solution

### Wi-Fi

Espressif has [a guide on low-power Wi-Fi](https://docs.espressif.com/projects/esp-idf/en/v5.5.1/esp32s3/api-guides/low-power-mode/low-power-mode-wifi.html). The development framework ESP-IDF provides an auto light-sleep functionality that maintains a connection in 1\~2 mA of power.

To maintain a Wi-Fi connection, the wireless modem peripheral periodically wakes up and communicates with the AP. Power save is achieved by automatically entering light-sleep mode when all FreeRTOS tasks are idle and no peripherals are running, with wireless modem interrupts waking up the processor occasionally. Thus, peripherals including I2S should be disabled for the power save to take effect; we will get to audio later.

There is an option `CONFIG_FREERTOS_IDLE_TIME_BEFORE_SLEEP` that sets the number of idle ticks to trigger the sleep, with `FREERTOS_HZ` controlling the frequency/duration of ticks. Both affect the average power consumption. The former (idle tick threshold) is set to the lowest possible value of 2. The latter (tick frequency) is more of a tradeoff: a high frequency/short duration reduces the time awake for each modem interrupt, but adds burden during load due to context switches. There is no dynamic scaling mechanism, so the sides have to be weighed. A tick rate of 500 Hz (2 ms) with default Wi-Fi driver options yields a low consumption of around 2 mA, with intermittent spikes to \~20 mA while staying \<1 mA most of the time.

### I2S clock

As the I2S peripheral stops in sleep mode, we need to supply the clock from somewhere else. In essence, the clock is simply 50%-duty PWM, so the options should be plenty. ESP32-S3 has two types of PWM timer peripherals: a motor-control type (MCPWM) and a general-use type (denoted LEDC). MCPWM cannot operate in sleep mode either, but LEDC can be clocked directly from external crystal (XTAL), making a perfect fit.

LEDC operates by feeding a timer (one of 4) to a channel (one of 8). Each timer is an upward counter with a 10.8 fractional divider and a configurable bit width (counts up to 2\^n - 1 and wraps around), clocked by a shared selected source (in our case, XTAL). Each channel has an h-point (phase) and a duty cycle (the reference manual mentions an "l-point", which simply means (h-point + duty) modulo 2\^n).

For the I2S clock, we need a 16-kHz WS signal and a 1024-kHz BCK signal, with aligned edges. A timer can only support one frequency, so we need two timers, each driving one channel. For example, with two timers both running at a counter frequency of 16384 kHz (2.44140625 subdivision from 40 MHz XTAL), WS timer wraparound is 10 bits (subdiv. 1024) and BCK, 4 bits (subdiv. 16).

However, even though the timers can be set to count at the same frequency, they cannot be synchronized or started/reset simultaneously. Timer control registers are separate for each timer, each 8 bytes apart, so the timers must be started through two register writes, which introduces offset and jitter. They can even misalign at sub-counter level, as the system bus runs faster than the timers' clock source (XTAL), not to mention the subdivided counters; both timer resets and counter value reads may be off by fractions of a counter. This presents a prominent hindrance.

In theory, we can mitigate this as long as we can adjust the phase offset (h-point) of the WS channel; we only need to do it reliably and consistently. The timer counters can be directly read from the `LEDC_TIMER<n>_VALUE_REG` register; we can find the offset between the two timers if they share the same frequency. Once we know the offset, we can compensate for it in the h-point of the WS channel.

Now, the hardest problems may be solved with the simplest answers. To reliably find the counter offset, we sample many times, in each of which we get a counter offset within +/-1 consistency. Then we take an extreme value among them (e.g., the maximum).

```c
uint32_t cnt_diff_max;

// Sample many times and take the extreme value
for (int i = 0; i < 8; i++) {
  // Sample successively, with synchronization barriers
  uint32_t t1_cnt, t2_cnt;
  asm volatile (
    "isync\n"
    "l32i %[t1_cnt], %[addr1], 0\n" "memw\n"
    "l32i %[t2_cnt], %[addr2], 0\n" "memw\n"
    : [t1_cnt] "=&r" (t1_cnt),
      [t2_cnt] "=&r" (t2_cnt)
    : [addr1] "r" (LEDC_LSTIMER1_VALUE_REG),
      [addr2] "r" (LEDC_LSTIMER2_VALUE_REG)
  );

  // Fold the WS's wide counter down to BCK's 4-bit
  t2_cnt %= 16;
  // Record the first value, and update if
  // the new value moves up by less than a half-cycle
  uint32_t cnt_diff = (t2_cnt - t1_cnt + 16) % 16;
  if (i == 0 || (cnt_diff - cnt_diff_max + 16) % 16 < 8)
    cnt_diff_max = cnt_diff;

  // Print to inspect as well as provide more sampling phase variance
  portENABLE_INTERRUPTS();
  ESP_LOGI(TAG, "Timer 1 CNT %u, Timer 2 CNT %u, diff = %u",
    (unsigned)t1_cnt, (unsigned)t2_cnt, (unsigned)cnt_diff);
  portDISABLE_INTERRUPTS();
}

// Update WS channel h-point
// Extra -2 for finer alignment
REG_WRITE(LEDC_LSCH4_HPOINT_REG, 1024 - cnt_diff_max - 2);
REG_SET_BIT(LEDC_LSCH4_CONF0_REG, LEDC_PARA_UP_LSCH4);
```

In this way, we can obtain a pair of clock signals synchronized to a consistency within few system clocks, regardless of previous system state. We can further move the phase offset around consistently by adding a constant offset to the h-point, so that the two signals become aligned. (There can be a very slight misalignment; but as I2S is forgiving in timing, it does not matter by much in practice.)

![Logic analyzer capture of the tuned I2S clocks.](03_i2s_clocks.jpg)

*(Edit: In hindsight, WS should really fall on SCK's falling edge, rather than the rising edge as displayed in the above diagram. But the microphone has been working well on this setup anyway. This might be a testament of how forgiving I2S can be?)*

With XTAL and LEDC running in sleep (a `esp_sleep_pd_config(ESP_PD_DOMAIN_XTAL, ESP_PD_OPTION_ON)` call), combined with the microphone now in active state, the current consumption increases, to around 10 mA. Experiments show that the main contributor to consumption is the operation of XTAL during sleep; when said call is absent, consumption drops to the Wi-Fi baseline (but I2S no longer works).

### VAD

With the clock signals running, we can retrieve the audio data from the microphone, *while in sleep*.

ESP32-S3 has [an ultra-low-power (ULP) coprocessor](https://docs.espressif.com/projects/esp-idf/en/v5.5.1/esp32s3/api-reference/system/ulp.html) that resides in the RTC power/clock domain, capable of running in microamps when the main processor is in sleep. It can be configured as a RISC-V (RV32IMC) core, opening doors to a wide range of general computation.

The plan is obvious: put the main processor to sleep, and let ULP capture and analyze I2S data signals. We cannot read the LEDC state from ULP, but the RTC GPIO (pins 0 through 21) remains accessible, as is laid out in the technical reference manual (v. 1.7, chapters 2.8 and 6.7). ESP32-S3 does not provide a way to read a pin configured as a peripheral output, so we need to short each of WS and BCK to another pin for sampling.

The reference manual describes ULP as being clocked by the 17.5 MHz internal RC oscillator, but it forgets to mention that it can also be clocked right from XTAL/2 (20 MHz). Apart from a slight speed boost, we get a processor clock in lockstep with the LEDC outputs, which, as will be shown next, plays a crucial role.

First, data retrieval. It sounds simple as we only need to sample bits, but each memory/peripheral read instruction takes 9 cycles on the ULP, and a general computation instruction takes 5. Note that each half-period of a bit is (20 MHz / 1.024 MHz / 2) = 9.8 cycles, only marginally longer than a read operation, so we need to put all read values into the core registers and process at the end. Fortunately there are 31 general-purpose registers, leaving us with around 20 to use freely, so we can at least try to sample 8\~10 bits. We can find a falling edge of WS, and sample many bits immediately.

However, finding a falling edge by a loop easily takes 20 cycles per iteration due to instructions and branches, thus missing the most significant bit by chance. To improve reliability, we need an accurate method to find the edge. RISC-V provides an `rdcycle` instruction for the number of system clock cycles since boot; we can use the same technique as above (sample many times and take extreme value) to obtain a cycle offset of the WS clock, modulo the 1250-cycle (16 kHz) period. Only if we can do cycle-accurate delay, we can precisely land on the cycle that WS falls, because there is now no clock drift between LEDC and ULP.

ESP-IDF's `ulp_riscv_delay_cycles()` is [simply a spin loop](https://github.com/espressif/esp-idf/blob/v5.5.1/components/ulp/ulp_riscv/ulp_core/include/ulp_riscv_utils.h#L97-L106) which incurs a potential inconsistency of about +/-3 cycles. For an exact delay, I went great lengths to measure the instruction latency characteristics of ULP. An uncompressed 32-bit instruction takes 5 cycles when aligned to a word boundary and 6 when unaligned; a compressed 16-bit instruction takes 3; a memory access takes extra 4. We can then construct a collection of instruction sequences (sleds) that covers all cycle counts up from 5. See [assembly source](https://github.com/ayuusweetfish/Yun-Ying-Ya/blob/923e9f0/fw/main/ulp/sled.S). Each time, we spin on `rdcycle` until the distance to the target cycle number falls into a lower range, and then hops onto the corresponding sled, landing on the exact cycle — 1250 since the last time. This target number is empirically offset (repeatedly adjusted while insecting sampled bits), so that the instructions following the sled start sampling at the right time. The actual audio sample data are then obtained by successive RTC GPIO register reads into registers, guarded by bus contention checks (calculating `rdcycle` increment throughout the GPIO reads, discarding the entire audio sample if bus contention happens). In this way, we are able to reliably read out the most significant 10 bits. Consult [the C source](https://github.com/ayuusweetfish/Yun-Ying-Ya/blob/923e9f0/fw/main/ulp/main.c) for the actual implementation.

From this point onward, we can apply any simple VAD algorithm to the audio samples. For example, energy gating. Operation for each audio sample squeezes away time available for GPIO sampling, reducing effective bit depth to 8 bits, but that is still sufficient. When potential voice activity is detected, the ULP wakes up the main processor, which then: (1) reads a short audio segment from a ring buffer in the ULP's shared memory (to avoid loss of initial voice), and (2) instructs the ULP to switch to the slightly higher-definition 12-bit mode, without VAD, and keeps fetching audio data from the said buffer. All fetched audio is fed to ESP-SR's detection model. Wake-up word detection does not require high-quality audio; we thus avoid I2S wake-up when idle, utilizing the peripheral only during interaction when real dialogues take place.

The ULP adds negligible power consumption due to the low clock frequency and no power/clock domains added. Thus, the final idle-mode current is **10 mA**, rising to around 40 mA when ESP-SR kicks in. This allows the device to idle for entire days!

## Ditched solutions

Alternatives have been researched and eliminated. An obvious route is to use a low-power MCU for the entire audio capture and VAD task, waking up the ESP32 when necessary. For example, PY32F003 specifies a 1-mA consumption when operating at 24 MHz. This allows for far more complex VAD algorithms due to PY32's DMA and faster computation, but takes up considerable board space — while this is indeed unfair to say of QFN20 packages, note that we're targeting 12-mm dimensions on a two-layer board, using an ESP32-S3 SiP that packages everything inside including the crystal, so any addition can be significant. In addition, buffering and streaming data between the chips adds dynamic dissipation and can get tricky to implement. Despite the shortcomings, there is a foreseeable power saving, because the reduction by gating the ESP32's RTC domain is rather large (10 mA baseline), so this solution may worth an attempt on another day.

The framework configuration seems to leave little room for improvement. The maximum system clock is currently set at 240 MHz, and lowering it to 160 MHz made no noticeable difference in Wi-Fi wake-up power spikes, at least when estimated on a DMM.

Another path, for sure, is to switch to a low-power RF SoC, possibly together with a low-power MCU. However, detecting the voiced word accurately is a non-trivial task requiring a considerable amount of computation and memory, severely limiting the lower bound of power; it's also not easy to make a detection model at home. Specialized wake-word solutions exist, but none so far beats the compactness and openness of Espressif's solutions, the narrow aperture of whose delicate possibilities have led me onto this uncharted path. I guess that is quite serendipitous a vendor lock-in (\> -)
